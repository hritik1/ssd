{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ssd_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CjdkO65i9wQl"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dzb4WU09bd_"
      },
      "source": [
        "!rm -rf sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQV9jeNa84wF",
        "outputId": "cca8ea4f-f62f-42f6-a063-0e773b941089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goEfu1_hNZUP",
        "outputId": "218db857-ebe7-4f28-ed19-719aa72ef7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 05:36:48--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.96.211\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.96.211|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  47.9MB/s    in 8m 9s   \n",
            "\n",
            "2020-09-20 05:44:57 (37.7 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu42A3PZl8J6"
      },
      "source": [
        "%%capture\n",
        "!unzip train2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDuCcxF66AJW"
      },
      "source": [
        "!rm -rf train2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9QGSEQXYRmy",
        "outputId": "9e5ff949-b2fb-48cf-a647-4bbaa7ef16ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 05:54:06--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.200.27\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.200.27|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip’\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  56.2MB/s    in 13s     \n",
            "\n",
            "2020-09-20 05:54:19 (60.4 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjglif3l9_D"
      },
      "source": [
        "%%capture\n",
        "!unzip val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJGbilXf6J6v"
      },
      "source": [
        "!rm -rf val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkfB7uvelstr",
        "outputId": "96eb0ce2-047d-4ec2-80a9-2f611768d38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 05:54:25--  http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.137.156\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.137.156|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1148688564 (1.1G) [application/zip]\n",
            "Saving to: ‘stuff_annotations_trainval2017.zip’\n",
            "\n",
            "stuff_annotations_t 100%[===================>]   1.07G  30.2MB/s    in 23s     \n",
            "\n",
            "2020-09-20 05:54:47 (48.3 MB/s) - ‘stuff_annotations_trainval2017.zip’ saved [1148688564/1148688564]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrPMTHLjlxvE"
      },
      "source": [
        "%%capture\n",
        "!unzip stuff_annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMQLMSTU6Njz"
      },
      "source": [
        "!rm -rf stuff_annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPk-HVsvlnsl",
        "outputId": "80d9d743-66c8-4bc8-fd31-ace3122a9899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 05:55:32--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.250.132\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.250.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  51.6MB/s    in 5.3s    \n",
            "\n",
            "2020-09-20 05:55:38 (45.3 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFXcYFirl6cp"
      },
      "source": [
        "%%capture\n",
        "!unzip annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK4P8eSQ6VPb"
      },
      "source": [
        "!rm -rf annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_QarkJomAtM",
        "outputId": "b44b723c-009d-4bb6-9af0-2c50fae0a740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "!pip install gluoncv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d7/74b530c461ac3eb90f6045a645a59450de1f3d616a4926e371daa021dbd8/gluoncv-0.8.0-py2.py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gluoncv) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gluoncv) (2.23.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->gluoncv) (1.15.0)\n",
            "Installing collected packages: portalocker, gluoncv\n",
            "Successfully installed gluoncv-0.8.0 portalocker-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW5RZzUhmCv1",
        "outputId": "dd70b4e6-0791-4573-aede-0215f410f2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/bb/54cbabe428351c06d10903c658878d29ee7026efbe45133fd133598d6eb6/mxnet-1.7.0.post1-py2.py3-none-manylinux2014_x86_64.whl (55.0MB)\n",
            "\u001b[K     |████████████████████████████████| 55.0MB 53kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.7.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGA_5pkWmGgJ",
        "outputId": "efb1b7d9-d87d-4af7-b599-e3898dfc2359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations  drive  train2017  val2017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj2lG4_in-tf",
        "outputId": "8e592a10-7783-4e68-9e18-5c26eed80857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from gluoncv import data, utils\n",
        "from matplotlib import pyplot as plt\n",
        " \n",
        "train_dataset = data.COCODetection('.',splits=['instances_train2017'])\n",
        "print('Num of training images:', len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=14.47s)\n",
            "creating index...\n",
            "index created!\n",
            "Num of training images: 117266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOnxhQoGtfBe"
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9AEub3X2KCM"
      },
      "source": [
        "classes = ['image']\n",
        "class_id = [22,25,6,16,5,3,8,7,1,20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mH_ZjRnlGjz"
      },
      "source": [
        "def check(class_id,class_ids):\n",
        "  a = 0\n",
        "  for i in range(0,len(class_id)):\n",
        "    if class_id[i] in class_ids:\n",
        "      a += 1\n",
        "  if a != 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvJsoUfit3F5",
        "outputId": "dbdb3371-47bb-4ca4-954b-c056cfd08fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import cv2\n",
        "import os\n",
        " \n",
        "n=0\n",
        "imgFolder = 'images'\n",
        "with open('label.txt', 'w') as myfile:\n",
        "  for i in range(len(train_dataset)):\n",
        "    if i % 500 == 0:\n",
        "      print(i)\n",
        "      print('images of interest',n)\n",
        "    train_image, train_label = train_dataset[i]\n",
        "    bounding_boxes = train_label[:, :4]\n",
        "    class_ids = train_label[:, 4:5] \n",
        "    if check(class_id,class_ids):     \n",
        "      name = classes[0]+str(n)\n",
        "      imgPath = os.path.join(imgFolder, name) +'.jpg'\n",
        "      image = train_image.asnumpy()\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      cv2.imwrite(imgPath,image)    \n",
        "      for j in range(len(class_ids)):\n",
        "        if class_ids[j] in class_id: \n",
        "          x1 = int(bounding_boxes[j][0])\n",
        "          y1 = int(bounding_boxes[j][1])\n",
        "          x2 = int(bounding_boxes[j][2])\n",
        "          y2 = int(bounding_boxes[j][3])\n",
        "          line = imgPath + \" \" + str(int(class_ids[j][0])) + \" \" + str(x1) + \" \" + str(y1) + \" \" + str(x2) + \" \" + str(y2)\n",
        "          myfile.write(line + \"\\n\")\n",
        "      n += 1\n",
        "      \n",
        "  print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "images of interest 0\n",
            "500\n",
            "images of interest 130\n",
            "1000\n",
            "images of interest 260\n",
            "1500\n",
            "images of interest 395\n",
            "2000\n",
            "images of interest 525\n",
            "2500\n",
            "images of interest 666\n",
            "3000\n",
            "images of interest 793\n",
            "3500\n",
            "images of interest 918\n",
            "4000\n",
            "images of interest 1050\n",
            "4500\n",
            "images of interest 1179\n",
            "5000\n",
            "images of interest 1316\n",
            "5500\n",
            "images of interest 1458\n",
            "6000\n",
            "images of interest 1603\n",
            "6500\n",
            "images of interest 1727\n",
            "7000\n",
            "images of interest 1831\n",
            "7500\n",
            "images of interest 1957\n",
            "8000\n",
            "images of interest 2093\n",
            "8500\n",
            "images of interest 2228\n",
            "9000\n",
            "images of interest 2362\n",
            "9500\n",
            "images of interest 2487\n",
            "10000\n",
            "images of interest 2612\n",
            "10500\n",
            "images of interest 2741\n",
            "11000\n",
            "images of interest 2862\n",
            "11500\n",
            "images of interest 2985\n",
            "12000\n",
            "images of interest 3116\n",
            "12500\n",
            "images of interest 3250\n",
            "13000\n",
            "images of interest 3377\n",
            "13500\n",
            "images of interest 3514\n",
            "14000\n",
            "images of interest 3647\n",
            "14500\n",
            "images of interest 3761\n",
            "15000\n",
            "images of interest 3885\n",
            "15500\n",
            "images of interest 4010\n",
            "16000\n",
            "images of interest 4133\n",
            "16500\n",
            "images of interest 4256\n",
            "17000\n",
            "images of interest 4382\n",
            "17500\n",
            "images of interest 4508\n",
            "18000\n",
            "images of interest 4641\n",
            "18500\n",
            "images of interest 4765\n",
            "19000\n",
            "images of interest 4894\n",
            "19500\n",
            "images of interest 5022\n",
            "20000\n",
            "images of interest 5168\n",
            "20500\n",
            "images of interest 5289\n",
            "21000\n",
            "images of interest 5427\n",
            "21500\n",
            "images of interest 5543\n",
            "22000\n",
            "images of interest 5694\n",
            "22500\n",
            "images of interest 5811\n",
            "23000\n",
            "images of interest 5953\n",
            "23500\n",
            "images of interest 6088\n",
            "24000\n",
            "images of interest 6221\n",
            "24500\n",
            "images of interest 6340\n",
            "25000\n",
            "images of interest 6477\n",
            "25500\n",
            "images of interest 6606\n",
            "26000\n",
            "images of interest 6739\n",
            "26500\n",
            "images of interest 6868\n",
            "27000\n",
            "images of interest 7002\n",
            "27500\n",
            "images of interest 7132\n",
            "28000\n",
            "images of interest 7273\n",
            "28500\n",
            "images of interest 7405\n",
            "29000\n",
            "images of interest 7525\n",
            "29500\n",
            "images of interest 7670\n",
            "30000\n",
            "images of interest 7800\n",
            "30500\n",
            "images of interest 7931\n",
            "31000\n",
            "images of interest 8051\n",
            "31500\n",
            "images of interest 8169\n",
            "32000\n",
            "images of interest 8292\n",
            "32500\n",
            "images of interest 8437\n",
            "33000\n",
            "images of interest 8564\n",
            "33500\n",
            "images of interest 8706\n",
            "34000\n",
            "images of interest 8818\n",
            "34500\n",
            "images of interest 8947\n",
            "35000\n",
            "images of interest 9098\n",
            "35500\n",
            "images of interest 9216\n",
            "36000\n",
            "images of interest 9350\n",
            "36500\n",
            "images of interest 9476\n",
            "37000\n",
            "images of interest 9606\n",
            "37500\n",
            "images of interest 9746\n",
            "38000\n",
            "images of interest 9880\n",
            "38500\n",
            "images of interest 10008\n",
            "39000\n",
            "images of interest 10124\n",
            "39500\n",
            "images of interest 10242\n",
            "40000\n",
            "images of interest 10369\n",
            "40500\n",
            "images of interest 10519\n",
            "41000\n",
            "images of interest 10629\n",
            "41500\n",
            "images of interest 10754\n",
            "42000\n",
            "images of interest 10863\n",
            "42500\n",
            "images of interest 10998\n",
            "43000\n",
            "images of interest 11115\n",
            "43500\n",
            "images of interest 11240\n",
            "44000\n",
            "images of interest 11378\n",
            "44500\n",
            "images of interest 11509\n",
            "45000\n",
            "images of interest 11632\n",
            "45500\n",
            "images of interest 11780\n",
            "46000\n",
            "images of interest 11902\n",
            "46500\n",
            "images of interest 12037\n",
            "47000\n",
            "images of interest 12163\n",
            "47500\n",
            "images of interest 12285\n",
            "48000\n",
            "images of interest 12421\n",
            "48500\n",
            "images of interest 12574\n",
            "49000\n",
            "images of interest 12706\n",
            "49500\n",
            "images of interest 12826\n",
            "50000\n",
            "images of interest 12951\n",
            "50500\n",
            "images of interest 13087\n",
            "51000\n",
            "images of interest 13213\n",
            "51500\n",
            "images of interest 13341\n",
            "52000\n",
            "images of interest 13476\n",
            "52500\n",
            "images of interest 13605\n",
            "53000\n",
            "images of interest 13742\n",
            "53500\n",
            "images of interest 13877\n",
            "54000\n",
            "images of interest 14005\n",
            "54500\n",
            "images of interest 14139\n",
            "55000\n",
            "images of interest 14265\n",
            "55500\n",
            "images of interest 14403\n",
            "56000\n",
            "images of interest 14537\n",
            "56500\n",
            "images of interest 14659\n",
            "57000\n",
            "images of interest 14802\n",
            "57500\n",
            "images of interest 14930\n",
            "58000\n",
            "images of interest 15071\n",
            "58500\n",
            "images of interest 15222\n",
            "59000\n",
            "images of interest 15357\n",
            "59500\n",
            "images of interest 15495\n",
            "60000\n",
            "images of interest 15633\n",
            "60500\n",
            "images of interest 15759\n",
            "61000\n",
            "images of interest 15887\n",
            "61500\n",
            "images of interest 16014\n",
            "62000\n",
            "images of interest 16144\n",
            "62500\n",
            "images of interest 16275\n",
            "63000\n",
            "images of interest 16412\n",
            "63500\n",
            "images of interest 16538\n",
            "64000\n",
            "images of interest 16676\n",
            "64500\n",
            "images of interest 16800\n",
            "65000\n",
            "images of interest 16938\n",
            "65500\n",
            "images of interest 17059\n",
            "66000\n",
            "images of interest 17207\n",
            "66500\n",
            "images of interest 17338\n",
            "67000\n",
            "images of interest 17472\n",
            "67500\n",
            "images of interest 17601\n",
            "68000\n",
            "images of interest 17727\n",
            "68500\n",
            "images of interest 17841\n",
            "69000\n",
            "images of interest 17963\n",
            "69500\n",
            "images of interest 18097\n",
            "70000\n",
            "images of interest 18235\n",
            "70500\n",
            "images of interest 18372\n",
            "71000\n",
            "images of interest 18490\n",
            "71500\n",
            "images of interest 18610\n",
            "72000\n",
            "images of interest 18743\n",
            "72500\n",
            "images of interest 18862\n",
            "73000\n",
            "images of interest 18990\n",
            "73500\n",
            "images of interest 19106\n",
            "74000\n",
            "images of interest 19212\n",
            "74500\n",
            "images of interest 19340\n",
            "75000\n",
            "images of interest 19472\n",
            "75500\n",
            "images of interest 19613\n",
            "76000\n",
            "images of interest 19746\n",
            "76500\n",
            "images of interest 19881\n",
            "77000\n",
            "images of interest 20006\n",
            "77500\n",
            "images of interest 20153\n",
            "78000\n",
            "images of interest 20281\n",
            "78500\n",
            "images of interest 20413\n",
            "79000\n",
            "images of interest 20537\n",
            "79500\n",
            "images of interest 20687\n",
            "80000\n",
            "images of interest 20821\n",
            "80500\n",
            "images of interest 20965\n",
            "81000\n",
            "images of interest 21103\n",
            "81500\n",
            "images of interest 21247\n",
            "82000\n",
            "images of interest 21372\n",
            "82500\n",
            "images of interest 21507\n",
            "83000\n",
            "images of interest 21637\n",
            "83500\n",
            "images of interest 21768\n",
            "84000\n",
            "images of interest 21878\n",
            "84500\n",
            "images of interest 21997\n",
            "85000\n",
            "images of interest 22141\n",
            "85500\n",
            "images of interest 22268\n",
            "86000\n",
            "images of interest 22387\n",
            "86500\n",
            "images of interest 22518\n",
            "87000\n",
            "images of interest 22656\n",
            "87500\n",
            "images of interest 22777\n",
            "88000\n",
            "images of interest 22909\n",
            "88500\n",
            "images of interest 23053\n",
            "89000\n",
            "images of interest 23191\n",
            "89500\n",
            "images of interest 23313\n",
            "90000\n",
            "images of interest 23441\n",
            "90500\n",
            "images of interest 23570\n",
            "91000\n",
            "images of interest 23701\n",
            "91500\n",
            "images of interest 23822\n",
            "92000\n",
            "images of interest 23966\n",
            "92500\n",
            "images of interest 24092\n",
            "93000\n",
            "images of interest 24221\n",
            "93500\n",
            "images of interest 24347\n",
            "94000\n",
            "images of interest 24476\n",
            "94500\n",
            "images of interest 24612\n",
            "95000\n",
            "images of interest 24741\n",
            "95500\n",
            "images of interest 24862\n",
            "96000\n",
            "images of interest 24980\n",
            "96500\n",
            "images of interest 25110\n",
            "97000\n",
            "images of interest 25218\n",
            "97500\n",
            "images of interest 25350\n",
            "98000\n",
            "images of interest 25462\n",
            "98500\n",
            "images of interest 25578\n",
            "99000\n",
            "images of interest 25702\n",
            "99500\n",
            "images of interest 25826\n",
            "100000\n",
            "images of interest 25957\n",
            "100500\n",
            "images of interest 26087\n",
            "101000\n",
            "images of interest 26212\n",
            "101500\n",
            "images of interest 26348\n",
            "102000\n",
            "images of interest 26474\n",
            "102500\n",
            "images of interest 26602\n",
            "103000\n",
            "images of interest 26731\n",
            "103500\n",
            "images of interest 26842\n",
            "104000\n",
            "images of interest 26976\n",
            "104500\n",
            "images of interest 27097\n",
            "105000\n",
            "images of interest 27237\n",
            "105500\n",
            "images of interest 27388\n",
            "106000\n",
            "images of interest 27507\n",
            "106500\n",
            "images of interest 27631\n",
            "107000\n",
            "images of interest 27763\n",
            "107500\n",
            "images of interest 27878\n",
            "108000\n",
            "images of interest 28002\n",
            "108500\n",
            "images of interest 28133\n",
            "109000\n",
            "images of interest 28270\n",
            "109500\n",
            "images of interest 28386\n",
            "110000\n",
            "images of interest 28515\n",
            "110500\n",
            "images of interest 28648\n",
            "111000\n",
            "images of interest 28773\n",
            "111500\n",
            "images of interest 28884\n",
            "112000\n",
            "images of interest 29021\n",
            "112500\n",
            "images of interest 29150\n",
            "113000\n",
            "images of interest 29276\n",
            "113500\n",
            "images of interest 29410\n",
            "114000\n",
            "images of interest 29548\n",
            "114500\n",
            "images of interest 29680\n",
            "115000\n",
            "images of interest 29805\n",
            "115500\n",
            "images of interest 29920\n",
            "116000\n",
            "images of interest 30051\n",
            "116500\n",
            "images of interest 30160\n",
            "117000\n",
            "images of interest 30291\n",
            "30355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ADRB8s05I2s"
      },
      "source": [
        "!rm -rf train2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxvmDl7_7kbl",
        "outputId": "04409e46-ef4c-4ac9-d992-a2f41fba7a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations  drive  images  label.txt  val2017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xs3dyTy2dvZ",
        "outputId": "ec6f9bbb-5c0a-4d1a-bf6e-a127ccc02434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "val_dataset = data.COCODetection('.',splits=['instances_val2017'])\n",
        "print('Num of validation images:', len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.88s)\n",
            "creating index...\n",
            "index created!\n",
            "Num of validation images: 4952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DhAEKIK9Erj"
      },
      "source": [
        "!mkdir val_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHvHWT9fEdbo",
        "outputId": "a9e2e4f9-8596-4d24-be8a-2179b715aa90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "import cv2\n",
        "import os\n",
        " \n",
        "n=0\n",
        "imgFolder = 'val_images'\n",
        "with open('val_label.txt', 'w') as myfile:\n",
        "  for i in range(len(val_dataset)):\n",
        "    if i % 500 == 0:\n",
        "      print(i)\n",
        "      print('images of interest',n)\n",
        "    val_image, val_label = val_dataset[i]\n",
        "    bounding_boxes = val_label[:, :4]\n",
        "    class_ids = val_label[:, 4:5] \n",
        "    if check(class_id,class_ids):     \n",
        "      name = classes[0]+str(n)\n",
        "      imgPath = os.path.join(imgFolder, name) +'.jpg'\n",
        "      image = val_image.asnumpy()\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      cv2.imwrite(imgPath,image)    \n",
        "      for j in range(len(class_ids)):\n",
        "        if class_ids[j] in class_id: \n",
        "          x1 = int(bounding_boxes[j][0])\n",
        "          y1 = int(bounding_boxes[j][1])\n",
        "          x2 = int(bounding_boxes[j][2])\n",
        "          y2 = int(bounding_boxes[j][3])\n",
        "          line = imgPath + \" \" + str(int(class_ids[j][0])) + \" \" + str(x1) + \" \" + str(y1) + \" \" + str(x2) + \" \" + str(y2)\n",
        "          myfile.write(line + \"\\n\")\n",
        "      n += 1\n",
        "      \n",
        "  print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "images of interest 0\n",
            "500\n",
            "images of interest 110\n",
            "1000\n",
            "images of interest 241\n",
            "1500\n",
            "images of interest 384\n",
            "2000\n",
            "images of interest 524\n",
            "2500\n",
            "images of interest 656\n",
            "3000\n",
            "images of interest 780\n",
            "3500\n",
            "images of interest 907\n",
            "4000\n",
            "images of interest 1030\n",
            "4500\n",
            "images of interest 1176\n",
            "1293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVTABDeZ6e-L"
      },
      "source": [
        "!rm -rf val2017\n",
        "!rm -rf annotations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuxNCeXj9wLQ"
      },
      "source": [
        "# Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRHdtnf9wLS"
      },
      "source": [
        "train_path = 'images'\n",
        "#test_path = '/home/hritik/global-wheat-detection/test'\n",
        "val_path = 'val_images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfQKiw_69wNY"
      },
      "source": [
        "#iIMPORTING ALL REQUIRED LIBRARIES\n",
        " \n",
        "import csv\n",
        "import math\n",
        "import glob\n",
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from random import randint\n",
        " \n",
        " \n",
        " \n",
        "import skimage\n",
        "from PIL import Image\n",
        "from skimage.util import random_noise\n",
        "from skimage import exposure\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55d2V2fM9wK5"
      },
      "source": [
        "label = open('label.txt','r')\n",
        "image_id = []\n",
        "index_id = []\n",
        "xmin = []\n",
        "ymin = []\n",
        "xmax = []\n",
        "ymax = [] \n",
        "for aline in label:\n",
        "    values = aline.split()\n",
        "    image_id.append(values[0][7:])\n",
        "    index_id.append(int(values[1]))\n",
        "    xmin.append(float(values[2]))\n",
        "    ymin.append(float(values[3]))\n",
        "    xmax.append(float(values[4]))\n",
        "    ymax.append(float(values[5]))\n",
        " \n",
        "df = {'image_id': image_id , 'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax,'class': index_id}\n",
        " \n",
        "data_frame = pd.DataFrame(data=df)\n",
        "data_frame.to_csv('train1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv3xLXIBGoqu",
        "outputId": "8b0eed93-4229-4230-be96-1063b7ced003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "train_csv = pd.read_csv('train1.csv')\n",
        "for i in range(0,len(train_csv['class'])):\n",
        "  if train_csv['class'][i] == 22:\n",
        "    train_csv['class'][i] = \"1\"\n",
        "  elif train_csv['class'][i] == 25:\n",
        "    train_csv['class'][i] = \"2\"\n",
        "  elif train_csv['class'][i] == 6:\n",
        "    train_csv['class'][i] = \"3\"\n",
        "  elif train_csv['class'][i] == 16:\n",
        "    train_csv['class'][i] = \"4\"\n",
        "  elif train_csv['class'][i] == 5:\n",
        "    train_csv['class'][i] = \"5\"\n",
        "  elif train_csv['class'][i] == 3:\n",
        "    train_csv['class'][i] = \"6\"\n",
        "  elif train_csv['class'][i] == 8:\n",
        "    train_csv['class'][i] = \"7\"\n",
        "  elif train_csv['class'][i] == 7:\n",
        "    train_csv['class'][i] = \"8\"\n",
        "  elif train_csv['class'][i] == 1:\n",
        "    train_csv['class'][i] = \"9\"\n",
        "  elif train_csv['class'][i] == 20:\n",
        "    train_csv['class'][i] = \"10\"\n",
        "train_csv.to_csv('train.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfwtDo65gqx9"
      },
      "source": [
        "label = open('val_label.txt','r')\n",
        "image_id = []\n",
        "index_id = []\n",
        "xmin = []\n",
        "ymin = []\n",
        "xmax = []\n",
        "ymax = [] \n",
        "for aline in label:\n",
        "    values = aline.split()\n",
        "    image_id.append(values[0][7:])\n",
        "    index_id.append(int(values[1]))\n",
        "    xmin.append(float(values[2]))\n",
        "    ymin.append(float(values[3]))\n",
        "    xmax.append(float(values[4]))\n",
        "    ymax.append(float(values[5]))\n",
        " \n",
        "df = {'image_id': image_id , 'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax,'class': index_id}\n",
        " \n",
        "data_frame = pd.DataFrame(data=df)\n",
        "data_frame.to_csv('val1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pcGWaC-g0x-",
        "outputId": "1b9297d6-1764-4830-ee23-daba07c65832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "train_csv = pd.read_csv('val1.csv')\n",
        "for i in range(0,len(train_csv['class'])):\n",
        "  if train_csv['class'][i] == 22:\n",
        "    train_csv['class'][i] = \"1\"\n",
        "  elif train_csv['class'][i] == 25:\n",
        "    train_csv['class'][i] = \"2\"\n",
        "  elif train_csv['class'][i] == 6:\n",
        "    train_csv['class'][i] = \"3\"\n",
        "  elif train_csv['class'][i] == 16:\n",
        "    train_csv['class'][i] = \"4\"\n",
        "  elif train_csv['class'][i] == 5:\n",
        "    train_csv['class'][i] = \"5\"\n",
        "  elif train_csv['class'][i] == 3:\n",
        "    train_csv['class'][i] = \"6\"\n",
        "  elif train_csv['class'][i] == 8:\n",
        "    train_csv['class'][i] = \"7\"\n",
        "  elif train_csv['class'][i] == 7:\n",
        "    train_csv['class'][i] = \"8\"\n",
        "  elif train_csv['class'][i] == 1:\n",
        "    train_csv['class'][i] = \"9\"\n",
        "  elif train_csv['class'][i] == 20:\n",
        "    train_csv['class'][i] = \"10\"\n",
        "train_csv.to_csv('val.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLw4G5wo9xID"
      },
      "source": [
        "!rm -rf label.txt\n",
        "!rm -rf train1.csv\n",
        "!rm -rf val1.csv\n",
        "!rm -rf val_label.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19D8DiJy9wNT"
      },
      "source": [
        "# Data Preprocessing + Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyTSuk0g9wNp"
      },
      "source": [
        "# OFFSET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQfw22d59wN2"
      },
      "source": [
        "input_shape = (640,480,3)\n",
        "image_shape = (640,480)\n",
        "n_classes = 10 + 1\n",
        "aspect_ratio = (1,2,1/2)\n",
        "n_layers = 8\n",
        "n_anchors = len(aspect_ratio) + 1\n",
        "width,height,channels =  input_shape\n",
        "threshold = 0.5\n",
        "verbose = 1\n",
        "batch_size = 1\n",
        "epochs = 10\n",
        " \n",
        "normalize = False\n",
        "class_threshold = 0.9\n",
        "soft_nms = False\n",
        "iou_threshold = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRb6_0h9wOC"
      },
      "source": [
        "params = {\n",
        "        'epoch_offset': 1,\n",
        "        'classes' : [\"zebra\",\"person\",\"train\",\"Dog\",\"Bus\",\"Bike\",\"Ship\",\"truck\",\"cycle\",\"Elephant\"]\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzrIko49wOL"
      },
      "source": [
        "# LEARNING RATE SCHEDULAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkolspk-9wOO"
      },
      "source": [
        "def lr_scheduler(epoch):\n",
        "    lr = 0.001\n",
        "    epoch_offset = params['epoch_offset']\n",
        "    if epoch > (1 - epoch_offset):\n",
        "        lr = lr/10\n",
        "    elif epoch > (4 - epoch_offset):\n",
        "        lr = lr/10\n",
        "    elif epoch > (8 - epoch_offset):\n",
        "        lr = lr/10\n",
        "    elif epoch > (12 - epoch_offset):\n",
        "        lr = lr/10\n",
        "    print('Learning rate: ', lr)\n",
        "    \n",
        "    return lr\n",
        " \n",
        " \n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1OrShY89wOW"
      },
      "source": [
        "# CREATING LABEL DICTIONARY FROM TRAIN CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7TFAgj9wOY"
      },
      "source": [
        "def get_box_color(index=None):\n",
        "    colors = ['w', 'r', 'b', 'g', 'c', 'm', 'y', 'g', 'c', 'm', 'k']\n",
        "    if index is None:\n",
        "        return colors[randint(0, len(colors) - 1)]\n",
        "    return colors[index % len(colors)]\n",
        " \n",
        "def show_labels(image, labels, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(1)\n",
        "        ax.imshow(image)\n",
        "    for label in labels:\n",
        "        # default label format is xmin, xmax, ymin, ymax\n",
        "        w = label[1] - label[0]\n",
        "        h = label[3] - label[2]\n",
        "        x = label[0]\n",
        "        y = label[2]\n",
        "        category = int(label[4])\n",
        "        color = get_box_color(category)\n",
        "        # Rectangle ((xmin, ymin), width, height) \n",
        "        rect = Rectangle((x, y),w,h,linewidth=2,edgecolor=color,facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "    plt.show()\n",
        "    \n",
        "def get_label_dictionary(labels, keys):\n",
        "    dictionary = {}\n",
        "    for key in keys:\n",
        "        dictionary[key] = [] # empty boxes\n",
        " \n",
        "    for label in labels:\n",
        "        if len(label) != 6:\n",
        "            print(\"Incomplete label:\", label[0])\n",
        "            continue\n",
        " \n",
        "        value = label[1:]\n",
        " \n",
        "        if value[0]==value[1]:\n",
        "            continue\n",
        "        if value[2]==value[3]:\n",
        "            continue\n",
        " \n",
        "        if label[-1]==0:\n",
        "            print(\"No object labelled as bg:\", label[0])\n",
        "            continue\n",
        " \n",
        "        # box coords are float32\n",
        "        value = value.astype(np.float32)\n",
        "        # filename is key\n",
        "        key = label[0]\n",
        "        # boxes = bounding box coords and class label\n",
        "        boxes = dictionary[key]\n",
        "        boxes.append(value)\n",
        "        dictionary[key] = boxes\n",
        " \n",
        "    # remove dataset entries w/o labels\n",
        "    for key in keys:\n",
        "        if len(dictionary[key]) == 0:\n",
        "            del dictionary[key]\n",
        " \n",
        "    return dictionary\n",
        " \n",
        "def load_csv(path):\n",
        "    data = []\n",
        "    with open(path) as csv_file:\n",
        "        rows = csv.reader(csv_file, delimiter=',')\n",
        "        for row in rows:\n",
        "            data.append(row)\n",
        " \n",
        "    return np.array(data)\n",
        " \n",
        "def build_label_dictionary(path):\n",
        "    labels = load_csv(path)\n",
        "    # skip the 1st line header\n",
        "    labels = labels[1:]\n",
        "    # keys are filenames\n",
        "    keys = np.unique(labels[:,0])\n",
        "    dictionary = get_label_dictionary(labels, keys)\n",
        "    classes = np.unique(labels[:,-1]).astype(int).tolist()\n",
        "    # insert background label 0\n",
        "    classes.insert(0, 0)\n",
        "    print(\"Num of unique classes: \", classes)\n",
        "    return dictionary, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKhDmcRP9wOg"
      },
      "source": [
        "# IoU FOR GROUND TRUTH BOXES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXuCCX99wOj"
      },
      "source": [
        "def anchor_sizes(n_layers=n_layers):\n",
        "    s = np.linspace(0.2, 0.9, n_layers + 1)\n",
        "    sizes = []\n",
        "    for i in range(len(s) - 1):\n",
        "        size = [s[i], math.sqrt(s[i] * s[i + 1])]\n",
        "        sizes.append(size)\n",
        " \n",
        "    return sizes\n",
        " \n",
        " \n",
        "def anchor_boxes(feature_shape,image_shape,index=0,n_layers=n_layers,aspect_ratios = aspect_ratio):\n",
        "    #anchor box sizes given an index of layer in ssd head\n",
        "    sizes = anchor_sizes(n_layers)[index]\n",
        "    # number of anchor boxes per feature map pt\n",
        "    n_boxes = len(aspect_ratios) + 1\n",
        "    # ignore number of channels (last)\n",
        "    image_height, image_width, _ = image_shape\n",
        "    # ignore number of feature maps (last)\n",
        "    feature_height, feature_width, _ = feature_shape\n",
        " \n",
        "    # normalized width and height\n",
        "    # sizes[0] is scale size, sizes[1] is sqrt(scale*(scale+1))\n",
        "    norm_height = image_height * sizes[0]\n",
        "    norm_width = image_width * sizes[0]\n",
        " \n",
        "    # list of anchor boxes (width, height)\n",
        "    width_height = []\n",
        "    # anchor box by aspect ratio on resized image dims\n",
        "    # Equation 11.2.3 \n",
        "    for ar in aspect_ratios:\n",
        "        box_width = norm_width * np.sqrt(ar)\n",
        "        box_height = norm_height / np.sqrt(ar)\n",
        "        width_height.append((box_width, box_height))\n",
        "    # multiply anchor box dim by size[1] for aspect_ratio = 1\n",
        "    # Equation 11.2.4\n",
        "    box_width = image_width * sizes[1]\n",
        "    box_height = image_height * sizes[1]\n",
        "    width_height.append((box_width, box_height))\n",
        " \n",
        "    # now an array of (width, height)\n",
        "    width_height = np.array(width_height)\n",
        " \n",
        "    # dimensions of each receptive field in pixels\n",
        "    grid_width = image_width / feature_width\n",
        "    grid_height = image_height / feature_height\n",
        " \n",
        "    # compute center of receptive field per feature pt\n",
        "    # (cx, cy) format \n",
        "    # starting at midpoint of 1st receptive field\n",
        "    start = grid_width * 0.5 \n",
        "    # ending at midpoint of last receptive field\n",
        "    end = (feature_width - 0.5) * grid_width\n",
        "    cx = np.linspace(start, end, feature_width)\n",
        " \n",
        "    start = grid_height * 0.5\n",
        "    end = (feature_height - 0.5) * grid_height\n",
        "    cy = np.linspace(start, end, feature_height)\n",
        " \n",
        "    # grid of box centers\n",
        "    cx_grid, cy_grid = np.meshgrid(cx, cy)\n",
        " \n",
        "    # for np.tile()\n",
        "    cx_grid = np.expand_dims(cx_grid, -1) \n",
        "    cy_grid = np.expand_dims(cy_grid, -1)\n",
        " \n",
        "    # tensor = (feature_map_height, feature_map_width, n_boxes, 4)\n",
        "    # aligned with image tensor (height, width, channels)\n",
        "    # last dimension = (cx, cy, w, h)\n",
        "    boxes = np.zeros((feature_height, feature_width, n_boxes, 4))\n",
        "    \n",
        "    # (cx, cy)\n",
        "    boxes[..., 0] = np.tile(cx_grid, (1, 1, n_boxes))\n",
        "    boxes[..., 1] = np.tile(cy_grid, (1, 1, n_boxes))\n",
        " \n",
        "    # (w, h)\n",
        "    boxes[..., 2] = width_height[:, 0]\n",
        "    boxes[..., 3] = width_height[:, 1]\n",
        " \n",
        "    # convert (cx, cy, w, h) to (xmin, xmax, ymin, ymax)\n",
        "    # prepend one dimension to boxes \n",
        "    # to account for the batch size = 1\n",
        "    boxes = centroid2minmax(boxes)\n",
        "    boxes = np.expand_dims(boxes, axis=0)\n",
        "    return boxes\n",
        " \n",
        " \n",
        "def centroid2minmax(boxes):\n",
        "    minmax= np.copy(boxes).astype(np.float)\n",
        "    minmax[..., 0] = boxes[..., 0] - (0.5 * boxes[..., 2])\n",
        "    minmax[..., 1] = boxes[..., 0] + (0.5 * boxes[..., 2])\n",
        "    minmax[..., 2] = boxes[..., 1] - (0.5 * boxes[..., 3])\n",
        "    minmax[..., 3] = boxes[..., 1] + (0.5 * boxes[..., 3])\n",
        "    return minmax\n",
        " \n",
        " \n",
        "def minmax2centroid(boxes):\n",
        "    centroid = np.copy(boxes).astype(np.float)\n",
        "    centroid[..., 0] = 0.5 * (boxes[..., 1] - boxes[..., 0])\n",
        "    centroid[..., 0] += boxes[..., 0] \n",
        "    centroid[..., 1] = 0.5 * (boxes[..., 3] - boxes[..., 2])\n",
        "    centroid[..., 1] += boxes[..., 2] \n",
        "    centroid[..., 2] = boxes[..., 1] - boxes[..., 0]\n",
        "    centroid[..., 3] = boxes[..., 3] - boxes[..., 2]\n",
        "    return centroid\n",
        " \n",
        " \n",
        " \n",
        "def intersection(boxes1, boxes2):\n",
        "    m = boxes1.shape[0] # The number of boxes in `boxes1`\n",
        "    n = boxes2.shape[0] # The number of boxes in `boxes2`\n",
        " \n",
        "    xmin = 0\n",
        "    xmax = 1\n",
        "    ymin = 2\n",
        "    ymax = 3\n",
        " \n",
        "    boxes1_min = np.expand_dims(boxes1[:, [xmin, ymin]], axis=1)\n",
        "    boxes1_min = np.tile(boxes1_min, reps=(1, n, 1))\n",
        "    boxes2_min = np.expand_dims(boxes2[:, [xmin, ymin]], axis=0)\n",
        "    boxes2_min = np.tile(boxes2_min, reps=(m, 1, 1))\n",
        "    min_xy = np.maximum(boxes1_min, boxes2_min)\n",
        " \n",
        "    boxes1_max = np.expand_dims(boxes1[:, [xmax, ymax]], axis=1)\n",
        "    boxes1_max = np.tile(boxes1_max, reps=(1, n, 1))\n",
        "    boxes2_max = np.expand_dims(boxes2[:, [xmax, ymax]], axis=0)\n",
        "    boxes2_max = np.tile(boxes2_max, reps=(m, 1, 1))\n",
        "    max_xy = np.minimum(boxes1_max, boxes2_max)\n",
        " \n",
        "    side_lengths = np.maximum(0, max_xy - min_xy)\n",
        " \n",
        "    intersection_areas = side_lengths[:, :, 0] * side_lengths[:, :, 1]\n",
        "    return intersection_areas\n",
        " \n",
        " \n",
        "def union(boxes1, boxes2, intersection_areas):\n",
        "    m = boxes1.shape[0] # number of boxes in boxes1\n",
        "    n = boxes2.shape[0] # number of boxes in boxes2\n",
        " \n",
        "    xmin = 0\n",
        "    xmax = 1\n",
        "    ymin = 2\n",
        "    ymax = 3\n",
        " \n",
        "    width = (boxes1[:, xmax] - boxes1[:, xmin])\n",
        "    height = (boxes1[:, ymax] - boxes1[:, ymin])\n",
        "    areas = width * height\n",
        "    boxes1_areas = np.tile(np.expand_dims(areas, axis=1), reps=(1,n))\n",
        "    width = (boxes2[:,xmax] - boxes2[:,xmin])\n",
        "    height = (boxes2[:,ymax] - boxes2[:,ymin])\n",
        "    areas = width * height\n",
        "    boxes2_areas = np.tile(np.expand_dims(areas, axis=0), reps=(m,1))\n",
        " \n",
        "    union_areas = boxes1_areas + boxes2_areas - intersection_areas\n",
        "    return union_areas\n",
        " \n",
        " \n",
        "def iou(boxes1, boxes2):\n",
        "    intersection_areas = intersection(boxes1, boxes2)\n",
        "    union_areas = union(boxes1, boxes2, intersection_areas)\n",
        "    return intersection_areas / union_areas\n",
        " \n",
        " \n",
        "def get_gt_data(iou,n_classes=4,anchors=None,labels=None,normalize=False,threshold=threshold):\n",
        " \n",
        "    # each maxiou_per_get is index of anchor w/ max iou\n",
        "    # for the given ground truth bounding box\n",
        "    maxiou_per_gt = np.argmax(iou, axis=0)\n",
        "    \n",
        "    # get extra anchor boxes based on IoU\n",
        "    if threshold < 1.0:\n",
        "        iou_gt_thresh = np.argwhere(iou>threshold)\n",
        "        if iou_gt_thresh.size > 0:\n",
        "            extra_anchors = iou_gt_thresh[:,0]\n",
        "            extra_classes = iou_gt_thresh[:,1]\n",
        "            #extra_labels = labels[:,:][extra_classes]\n",
        "            extra_labels = labels[extra_classes]\n",
        "            indexes = [maxiou_per_gt, extra_anchors]\n",
        "            maxiou_per_gt = np.concatenate(indexes,\n",
        "                                           axis=0)\n",
        "            labels = np.concatenate([labels, extra_labels],\n",
        "                                    axis=0)\n",
        " \n",
        "    # mask generation\n",
        "    gt_mask = np.zeros((iou.shape[0], 4))\n",
        "    # only indexes maxiou_per_gt are valid bounding boxes\n",
        "    gt_mask[maxiou_per_gt] = 1.0\n",
        " \n",
        "    # class generation\n",
        "    gt_class = np.zeros((iou.shape[0], n_classes))\n",
        "    # by default all are background (index 0)\n",
        "    gt_class[:, 0] = 1\n",
        "    # but those that belong to maxiou_per_gt are not\n",
        "    gt_class[maxiou_per_gt, 0] = 0\n",
        "    # we have to find those column indexes (classes)\n",
        "    maxiou_col = np.reshape(maxiou_per_gt,\n",
        "                            (maxiou_per_gt.shape[0], 1))\n",
        "    label_col = np.reshape(labels[:,4],\n",
        "                           (labels.shape[0], 1)).astype(int)\n",
        "    row_col = np.append(maxiou_col, label_col, axis=1)\n",
        "    # the label of object in maxio_per_gt\n",
        "    gt_class[row_col[:,0], row_col[:,1]]  = 1.0\n",
        "    \n",
        "    # offsets generation\n",
        "    gt_offset = np.zeros((iou.shape[0], 4))\n",
        " \n",
        "    #(cx, cy, w, h) format\n",
        "    if normalize:\n",
        "        anchors = minmax2centroid(anchors)\n",
        "        labels = minmax2centroid(labels)\n",
        "        # bbox = bounding box\n",
        "        # ((bbox xcenter - anchor box xcenter)/anchor box width)/.1\n",
        "        # ((bbox ycenter - anchor box ycenter)/anchor box height)/.1\n",
        "        # Equation 11.4.8\n",
        "        offsets1 = labels[:, 0:2] - anchors[maxiou_per_gt, 0:2]\n",
        "        offsets1 /= anchors[maxiou_per_gt, 2:4]\n",
        "        offsets1 /= 0.1\n",
        " \n",
        "        # log(bbox width / anchor box width) / 0.2\n",
        "        # log(bbox height / anchor box height) / 0.2\n",
        "        # Equation 11.4.8 \n",
        "        offsets2 = np.log(labels[:, 2:4]/anchors[maxiou_per_gt, 2:4])\n",
        "        offsets2 /= 0.2  \n",
        " \n",
        "        offsets = np.concatenate([offsets1, offsets2], axis=-1)\n",
        " \n",
        "    # (xmin, xmax, ymin, ymax) format\n",
        "    else:\n",
        "        offsets = labels[:, 0:4] - anchors[maxiou_per_gt]\n",
        " \n",
        "    gt_offset[maxiou_per_gt] = offsets\n",
        " \n",
        "    return gt_class, gt_offset, gt_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTJK8y099wOr"
      },
      "source": [
        "# DATA GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GE4tedN9wOs"
      },
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                 layers,\n",
        "                 threshold,\n",
        "                 normalize,\n",
        "                 data_path,\n",
        "                 batch_size,\n",
        "                 dictionary,\n",
        "                 n_classes,\n",
        "                 feature_shapes=[],\n",
        "                 n_anchors=n_anchors,\n",
        "                 shuffle=True):\n",
        "        self.dictionary = dictionary\n",
        "        self.n_classes = n_classes\n",
        "        self.keys = np.array(list(self.dictionary.keys()))\n",
        "        self.input_shape = (height, width, channels)\n",
        "        self.feature_shapes = feature_shapes\n",
        "        self.n_anchors = n_anchors\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.get_n_boxes()\n",
        "        self.batch_size = batch_size\n",
        "        self.data_path = data_path\n",
        "        self.layers = layers\n",
        "        self.normalize = normalize\n",
        "        self.threshold = threshold\n",
        " \n",
        " \n",
        "    def __len__(self):\n",
        "        blen = np.floor(len(self.dictionary) / self.batch_size)\n",
        "        return int(blen)\n",
        " \n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = (index+1) * self.batch_size\n",
        "        keys = self.keys[start_index : end_index]\n",
        "        x, y = self.__data_generation(keys)\n",
        "        return x, y\n",
        " \n",
        " \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.keys)\n",
        " \n",
        " \n",
        "    def get_n_boxes(self):\n",
        "        self.n_boxes = 0\n",
        "        for shape in self.feature_shapes:\n",
        "            self.n_boxes += np.prod(shape) // self.n_anchors\n",
        "        return self.n_boxes\n",
        " \n",
        " \n",
        "    def apply_random_noise(self, image, percent=30):\n",
        "        random = np.random.randint(0, 100)\n",
        "        if random < percent:\n",
        "            image = random_noise(image)\n",
        "        return image\n",
        " \n",
        " \n",
        "    def apply_random_intensity_rescale(self, image, percent=30):\n",
        "        random = np.random.randint(0, 100)\n",
        "        if random < percent:\n",
        "            v_min, v_max = np.percentile(image, (0.2, 99.8))\n",
        "            image = exposure.rescale_intensity(image, in_range=(v_min, v_max))\n",
        "        return image\n",
        " \n",
        " \n",
        "    def apply_random_exposure_adjust(self, image, percent=30):\n",
        "        random = np.random.randint(0, 100)\n",
        "        if random < percent:\n",
        "            image = exposure.adjust_gamma(image, gamma=0.4, gain=0.9)\n",
        "            # another exposure algo\n",
        "            # image = exposure.adjust_log(image)\n",
        "        return image\n",
        " \n",
        " \n",
        "    def __data_generation(self, keys):\n",
        "    \n",
        "        # train input data\n",
        "        x = np.zeros((self.batch_size, *self.input_shape))\n",
        "        dim = (self.batch_size, self.n_boxes, self.n_classes)\n",
        "        # class ground truth\n",
        "        gt_class = np.zeros(dim)\n",
        "        dim = (self.batch_size, self.n_boxes, 4)\n",
        "        # offsets ground truth\n",
        "        gt_offset = np.zeros(dim)\n",
        "        # masks of valid bounding boxes\n",
        "        gt_mask = np.zeros(dim)\n",
        " \n",
        "        for i, key in enumerate(keys):\n",
        "            # images are assumed to be stored in self.data_path\n",
        "            # key is the image filename \n",
        "            image_path = os.path.join(self.data_path, key)\n",
        "            image = Image.open(image_path)\n",
        "            image = image.resize(image_shape)\n",
        "            image = skimage.img_as_float(image)\n",
        "            # assign image to a batch index\n",
        "            x[i] = image\n",
        "            # a label entry is made of 4-dim bounding box coords\n",
        "            # and 1-dim class label\n",
        "            labels = self.dictionary[key]\n",
        "            labels = np.array(labels)\n",
        "            # 4 bounding box coords are 1st four items of labels\n",
        "            # last item is object class label\n",
        "            boxes = labels[:,0:-1]\n",
        "            for index, feature_shape in enumerate(self.feature_shapes):\n",
        "                # generate anchor boxes\n",
        "                anchors = anchor_boxes(feature_shape,image.shape,index=index, n_layers=self.layers)\n",
        "                # each feature layer has a row of anchor boxes\n",
        "                anchors = np.reshape(anchors, [-1, 4])\n",
        "                # compute IoU of each anchor box \n",
        "                # with respect to each bounding boxes\n",
        "                iou1 = iou(anchors, boxes)\n",
        " \n",
        "                # generate ground truth class, offsets & mask\n",
        "                gt = get_gt_data(iou1,\n",
        "                                 n_classes=self.n_classes,\n",
        "                                 anchors=anchors,\n",
        "                                 labels=labels,\n",
        "                                 normalize=self.normalize,\n",
        "                                 threshold=self.threshold)\n",
        "                gt_cls, gt_off, gt_msk = gt\n",
        "                if index == 0:\n",
        "                    cls = np.array(gt_cls)\n",
        "                    off = np.array(gt_off)\n",
        "                    msk = np.array(gt_msk)\n",
        "                else:\n",
        "                    cls = np.append(cls, gt_cls, axis=0)\n",
        "                    off = np.append(off, gt_off, axis=0)\n",
        "                    msk = np.append(msk, gt_msk, axis=0)\n",
        " \n",
        "            gt_class[i] = cls\n",
        "            gt_offset[i] = off\n",
        "            gt_mask[i] = msk\n",
        " \n",
        " \n",
        "        y = [gt_class, np.concatenate((gt_offset, gt_mask), axis=-1)]\n",
        " \n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID7bQ-MlfIms"
      },
      "source": [
        "class Validation_DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                 layers,\n",
        "                 threshold,\n",
        "                 normalize,\n",
        "                 data_path,\n",
        "                 batch_size,\n",
        "                 dictionary,\n",
        "                 n_classes,\n",
        "                 feature_shapes=[],\n",
        "                 n_anchors=n_anchors,\n",
        "                 shuffle=True):\n",
        "        self.dictionary = dictionary\n",
        "        self.n_classes = n_classes\n",
        "        self.keys = np.array(list(self.dictionary.keys()))\n",
        "        self.input_shape = (height, width, channels)\n",
        "        self.feature_shapes = feature_shapes\n",
        "        self.n_anchors = n_anchors\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.get_n_boxes()\n",
        "        self.batch_size = batch_size\n",
        "        self.data_path = data_path\n",
        "        self.layers = layers\n",
        "        self.normalize = normalize\n",
        "        self.threshold = threshold\n",
        " \n",
        " \n",
        "    def __len__(self):\n",
        "        blen = np.floor(len(self.dictionary) / self.batch_size)\n",
        "        return int(blen)\n",
        " \n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = (index+1) * self.batch_size\n",
        "        keys = self.keys[start_index : end_index]\n",
        "        x, y = self.__data_generation(keys)\n",
        "        return x, y\n",
        " \n",
        " \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.keys)\n",
        " \n",
        " \n",
        "    def get_n_boxes(self):\n",
        "        self.n_boxes = 0\n",
        "        for shape in self.feature_shapes:\n",
        "            self.n_boxes += np.prod(shape) // self.n_anchors\n",
        "        return self.n_boxes\n",
        " \n",
        "    def __data_generation(self, keys):\n",
        "    \n",
        "        # train input data\n",
        "        x = np.zeros((self.batch_size, *self.input_shape))\n",
        "        dim = (self.batch_size, self.n_boxes, self.n_classes)\n",
        "        # class ground truth\n",
        "        gt_class = np.zeros(dim)\n",
        "        dim = (self.batch_size, self.n_boxes, 4)\n",
        "        # offsets ground truth\n",
        "        gt_offset = np.zeros(dim)\n",
        "        # masks of valid bounding boxes\n",
        "        gt_mask = np.zeros(dim)\n",
        " \n",
        "        for i, key in enumerate(keys):\n",
        "            # images are assumed to be stored in self.data_path\n",
        "            # key is the image filename \n",
        "            image_path = os.path.join(self.data_path, key)\n",
        "            image = Image.open(image_path)\n",
        "            image = image.resize(image_shape)\n",
        "            image = skimage.img_as_float(image)\n",
        "            # assign image to a batch index\n",
        "            x[i] = image\n",
        "            # a label entry is made of 4-dim bounding box coords\n",
        "            # and 1-dim class label\n",
        "            labels = self.dictionary[key]\n",
        "            labels = np.array(labels)\n",
        "            # 4 bounding box coords are 1st four items of labels\n",
        "            # last item is object class label\n",
        "            boxes = labels[:,0:-1]\n",
        "            for index, feature_shape in enumerate(self.feature_shapes):\n",
        "                # generate anchor boxes\n",
        "                anchors = anchor_boxes(feature_shape,image.shape,index=index, n_layers=self.layers)\n",
        "                # each feature layer has a row of anchor boxes\n",
        "                anchors = np.reshape(anchors, [-1, 4])\n",
        "                # compute IoU of each anchor box \n",
        "                # with respect to each bounding boxes\n",
        "                iou1 = iou(anchors, boxes)\n",
        " \n",
        "                # generate ground truth class, offsets & mask\n",
        "                gt = get_gt_data(iou1,\n",
        "                                 n_classes=self.n_classes,\n",
        "                                 anchors=anchors,\n",
        "                                 labels=labels,\n",
        "                                 normalize=self.normalize,\n",
        "                                 threshold=self.threshold)\n",
        "                gt_cls, gt_off, gt_msk = gt\n",
        "                if index == 0:\n",
        "                    cls = np.array(gt_cls)\n",
        "                    off = np.array(gt_off)\n",
        "                    msk = np.array(gt_msk)\n",
        "                else:\n",
        "                    cls = np.append(cls, gt_cls, axis=0)\n",
        "                    off = np.append(off, gt_off, axis=0)\n",
        "                    msk = np.append(msk, gt_msk, axis=0)\n",
        " \n",
        "            gt_class[i] = cls\n",
        "            gt_offset[i] = off\n",
        "            gt_mask[i] = msk\n",
        " \n",
        " \n",
        "        y = [gt_class, np.concatenate((gt_offset, gt_mask), axis=-1)]\n",
        " \n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIRzSiKh9wO1"
      },
      "source": [
        "# MODEL  : VGG16 SSD(6 SSD HEADS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7LspIbp9wO3"
      },
      "source": [
        "def conv2d(inputs,filters=32,kernel_size=3,strides=1,name = None):\n",
        "  conv = layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, kernel_initializer='he_normal',padding='same',name=name)\n",
        "  return conv(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfW-vS9m9wO_"
      },
      "source": [
        "outputs = []\n",
        "feature_shapes = []\n",
        "out_cls = []\n",
        "out_off = []\n",
        " \n",
        "input_1 = keras.Input(shape= input_shape, name=\"input_1\")\n",
        " \n",
        "x = layers.Conv2D(64,(3,3),activation='relu',padding = 'same',name = 'block1_conv1')(input_1)\n",
        "x = layers.Conv2D(64,(3,3),activation='relu',padding = 'same',name = 'block1_conv2')(x)\n",
        "x = layers.MaxPooling2D(name = 'block1_pool')(x)\n",
        " \n",
        "x = layers.Conv2D(128,(3,3),activation='relu',padding = 'same',name = 'block2_conv1')(x)\n",
        "x = layers.Conv2D(128,(3,3),activation='relu',padding = 'same',name = 'block2_conv2')(x)\n",
        "x = layers.MaxPooling2D(name = 'block2_pool')(x)\n",
        " \n",
        "x = layers.Conv2D(256,(3,3),activation='relu',padding = 'same',name = 'block3_conv1')(x)\n",
        "x = layers.Conv2D(256,(3,3),activation='relu',padding = 'same',name = 'block3_conv2')(x)\n",
        "x = layers.Conv2D(256,(3,3),activation='relu',padding = 'same',name = 'block3_conv3')(x)\n",
        "x = layers.MaxPooling2D(name = 'block3_pool')(x)\n",
        " \n",
        "x = layers.Conv2D(512,(3,3),activation='relu',padding = 'same',name = 'block4_conv1')(x)\n",
        "x = layers.Conv2D(512,(3,3),activation='relu',padding = 'same',name = 'block4_conv2')(x)\n",
        "x = layers.Conv2D(512,(3,3),activation='relu',strides = 2,name = 'block4_conv3')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        " \n",
        "x_4_6 = x\n",
        "classes  = conv2d(x_4_6, n_anchors*n_classes ,kernel_size=3,name = 'c_0')\n",
        "offsets  = conv2d(x_4_6, n_anchors*4, kernel_size=3,name = 'o_0')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        "x = layers.MaxPooling2D(name = 'block4_pool')(x)\n",
        " \n",
        " \n",
        "x = layers.Conv2D(512,(3,3),activation='relu',padding = 'same',name = 'block5_conv1')(x)\n",
        "x = layers.Conv2D(512,(3,3),activation='relu',padding = 'same',name = 'block5_conv2')(x)\n",
        "x = layers.Conv2D(512,(3,3),activation='relu',strides = 2,name = 'block5_conv3')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        " \n",
        "x_5_7 = x\n",
        "classes  = conv2d(x_5_7, n_anchors*n_classes ,kernel_size=3,name = 'c_1')\n",
        "offsets  = conv2d(x_5_7, n_anchors*4, kernel_size=3,name = 'o_1')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        " \n",
        "x_6_8 = layers.Conv2D(1024,(1,1),activation='relu',padding = 'same',name = 'conv6_1')(x_4_6)\n",
        "x_6_8 = layers.Conv2D(1024,(3,3),activation='elu',padding = 'same',name = 'conv6_2')(x_6_8)\n",
        " \n",
        "classes  = conv2d(x_6_8, n_anchors*n_classes ,kernel_size=3,name = 'c_2')\n",
        "offsets  = conv2d(x_6_8, n_anchors*4, kernel_size=3,name = 'o_2')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        " \n",
        "x_7_9 = layers.Conv2D(1024,(1,1),activation='relu',name = 'conv7_1')(x_5_7)\n",
        "x_7_9 = layers.Conv2D(1024,(3,3),activation='elu',padding = 'same',name = 'conv7_2')(x_7_9)\n",
        " \n",
        "classes  = conv2d(x_7_9, n_anchors*n_classes, kernel_size=3,name = 'c_3')\n",
        "offsets  = conv2d(x_7_9, n_anchors*4,kernel_size=3,name = 'o_3')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        "x_8_10 = layers.Conv2D(256,(1,1),activation='relu',name = 'conv8_1')(x_6_8)\n",
        "x_8_10 = layers.Conv2D(512,(3,3),activation='elu',strides = 2,name = 'conv8_2')(x_8_10)\n",
        " \n",
        "classes  = conv2d(x_8_10, n_anchors*n_classes ,kernel_size=3,name = 'c_4')\n",
        "offsets  = conv2d(x_8_10, n_anchors*4, kernel_size=3,name = 'o_4')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        " \n",
        "x_9_11 = layers.Conv2D(128,(1,1),activation='relu',name = 'conv9_1')(x_7_9)\n",
        "x_9_11 = layers.Conv2D(256,(3,3),activation='elu',strides = 1,name = 'conv9_2')(x_9_11)\n",
        " \n",
        "classes  = conv2d(x_9_11, n_anchors*n_classes ,kernel_size=3,name = 'c_5')\n",
        "offsets  = conv2d(x_9_11, n_anchors*4, kernel_size=3,name = 'o_5')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        "x_10 = layers.Conv2D(256,(1,1),activation='relu',name = 'conv10_1')(x_8_10)\n",
        "x_10 = layers.Conv2D(512,(3,3),activation='elu',strides = 2,name = 'conv10_2')(x_10)\n",
        " \n",
        "classes  = conv2d(x_10, n_anchors*n_classes ,kernel_size=3,name = 'c_6')\n",
        "offsets  = conv2d(x_10, n_anchors*4, kernel_size=3,name = 'o_6')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        "x_11 = layers.Conv2D(128,(1,1),activation='relu',name = 'conv11_1')(x_9_11)\n",
        "x_11 = layers.Conv2D(256,(3,3),activation='elu',strides = 1,name = 'conv12_2')(x_11)\n",
        " \n",
        "classes  = conv2d(x_11, n_anchors*n_classes ,kernel_size=3,name = 'c_7')\n",
        "offsets  = conv2d(x_11, n_anchors*4, kernel_size=3,name = 'o_7')\n",
        "shape = np.array(K.int_shape(offsets))[1:]\n",
        "feature_shapes.append(shape)\n",
        "classes = layers.Reshape((-1, n_classes))(classes)\n",
        "offsets = layers.Reshape((-1, 4))(offsets)\n",
        "offsets = [offsets, offsets]\n",
        "offsets = layers.Concatenate(axis=-1)(offsets)\n",
        "out_off.append(offsets)\n",
        "classes = layers.Activation('softmax')(classes)\n",
        "out_cls.append(classes)\n",
        " \n",
        " \n",
        "offsets = layers.Concatenate(axis=1)(out_off)\n",
        "classes = layers.Concatenate(axis=1)(out_cls)\n",
        " \n",
        "outputs = [classes, offsets]\n",
        " \n",
        "model = keras.Model(input_1, outputs,name='ssd_head')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2FoYR1l9wPH",
        "outputId": "e1bc0b54-b227-4132-9060-3f4676a83744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ssd_head\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 640, 480, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 640, 480, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 640, 480, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 320, 240, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 320, 240, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 320, 240, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 160, 120, 128 0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 160, 120, 256 295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 160, 120, 256 590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 160, 120, 256 590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 80, 60, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 80, 60, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 80, 60, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 39, 29, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 39, 29, 512)  2048        block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 14, 512)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 19, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 19, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 9, 6, 512)    2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 9, 6, 512)    2048        block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv6_1 (Conv2D)                (None, 39, 29, 1024) 525312      batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv7_1 (Conv2D)                (None, 9, 6, 1024)   525312      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv6_2 (Conv2D)                (None, 39, 29, 1024) 9438208     conv6_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv7_2 (Conv2D)                (None, 9, 6, 1024)   9438208     conv7_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv8_1 (Conv2D)                (None, 39, 29, 256)  262400      conv6_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv9_1 (Conv2D)                (None, 9, 6, 128)    131200      conv7_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv8_2 (Conv2D)                (None, 19, 14, 512)  1180160     conv8_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv9_2 (Conv2D)                (None, 7, 4, 256)    295168      conv9_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv10_1 (Conv2D)               (None, 19, 14, 256)  131328      conv8_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv11_1 (Conv2D)               (None, 7, 4, 128)    32896       conv9_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv10_2 (Conv2D)               (None, 9, 6, 512)    1180160     conv10_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv12_2 (Conv2D)               (None, 5, 2, 256)    295168      conv11_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "c_0 (Conv2D)                    (None, 39, 29, 44)   202796      batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "c_1 (Conv2D)                    (None, 9, 6, 44)     202796      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "c_2 (Conv2D)                    (None, 39, 29, 44)   405548      conv6_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "c_3 (Conv2D)                    (None, 9, 6, 44)     405548      conv7_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "c_4 (Conv2D)                    (None, 19, 14, 44)   202796      conv8_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "c_5 (Conv2D)                    (None, 7, 4, 44)     101420      conv9_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "c_6 (Conv2D)                    (None, 9, 6, 44)     202796      conv10_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "c_7 (Conv2D)                    (None, 5, 2, 44)     101420      conv12_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "o_0 (Conv2D)                    (None, 39, 29, 16)   73744       batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "o_1 (Conv2D)                    (None, 9, 6, 16)     73744       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "o_2 (Conv2D)                    (None, 39, 29, 16)   147472      conv6_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "o_3 (Conv2D)                    (None, 9, 6, 16)     147472      conv7_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "o_4 (Conv2D)                    (None, 19, 14, 16)   73744       conv8_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "o_5 (Conv2D)                    (None, 7, 4, 16)     36880       conv9_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "o_6 (Conv2D)                    (None, 9, 6, 16)     73744       conv10_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "o_7 (Conv2D)                    (None, 5, 2, 16)     36880       conv12_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 4524, 11)     0           c_0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 216, 11)      0           c_1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 4524, 11)     0           c_2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 216, 11)      0           c_3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 1064, 11)     0           c_4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 112, 11)      0           c_5[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 216, 11)      0           c_6[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 40, 11)       0           c_7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 4524, 4)      0           o_0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 216, 4)       0           o_1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 4524, 4)      0           o_2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 216, 4)       0           o_3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 1064, 4)      0           o_4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 112, 4)       0           o_5[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 216, 4)       0           o_6[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 40, 4)        0           o_7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 4524, 11)     0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 216, 11)      0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4524, 11)     0           reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 216, 11)      0           reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1064, 11)     0           reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 112, 11)      0           reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 216, 11)      0           reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 40, 11)       0           reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4524, 8)      0           reshape_1[0][0]                  \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 216, 8)       0           reshape_3[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4524, 8)      0           reshape_5[0][0]                  \n",
            "                                                                 reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 216, 8)       0           reshape_7[0][0]                  \n",
            "                                                                 reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1064, 8)      0           reshape_9[0][0]                  \n",
            "                                                                 reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 8)       0           reshape_11[0][0]                 \n",
            "                                                                 reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 216, 8)       0           reshape_13[0][0]                 \n",
            "                                                                 reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 40, 8)        0           reshape_15[0][0]                 \n",
            "                                                                 reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 10912, 11)    0           activation[0][0]                 \n",
            "                                                                 activation_1[0][0]               \n",
            "                                                                 activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 10912, 8)     0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 40,643,104\n",
            "Trainable params: 40,641,056\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVpMrUO39wPT"
      },
      "source": [
        "# MODEL LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmeIRyPR9wPU"
      },
      "source": [
        "def focal_loss_categorical(y_true, y_pred):\n",
        "    gamma = 2.0\n",
        "    alpha = 0.25\n",
        " \n",
        "    # scale to ensure sum of prob is 1.0\n",
        "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        " \n",
        "    # clip the prediction value to prevent NaN and Inf\n",
        "    epsilon = K.epsilon()\n",
        "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        " \n",
        "    # calculate cross entropy\n",
        "    cross_entropy = -y_true * K.log(y_pred)\n",
        " \n",
        "    # calculate focal loss\n",
        "    weight = alpha * K.pow(1 - y_pred, gamma)\n",
        "    cross_entropy *= weight\n",
        " \n",
        "    return K.sum(cross_entropy, axis=-1)\n",
        " \n",
        " \n",
        "def mask_offset(y_true, y_pred): \n",
        "    # 1st 4 are offsets\n",
        "    offset = y_true[..., 0:4]\n",
        "    # last 4 are mask\n",
        "    mask = y_true[..., 4:8]\n",
        "    # pred is actually duplicated for alignment\n",
        "    # either we get the 1st or last 4 offset pred\n",
        "    # and apply the mask\n",
        "    pred = y_pred[..., 0:4]\n",
        "    offset *= mask\n",
        "    pred *= mask\n",
        "    return offset, pred\n",
        " \n",
        " \n",
        "def l1_loss(y_true, y_pred):\n",
        "    offset, pred = mask_offset(y_true, y_pred)\n",
        "    # we can use L1\n",
        "    return K.mean(K.abs(pred - offset), axis=-1)\n",
        " \n",
        " \n",
        "def smooth_l1_loss(y_true, y_pred):\n",
        "    offset, pred = mask_offset(y_true, y_pred)\n",
        "    # Huber loss as approx of smooth L1\n",
        "    return Huber()(offset, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lix8zR2F9wPd"
      },
      "source": [
        "# IMAGE DICTIONARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kv5xrKQ9wPg",
        "outputId": "d4a60c09-a216-4b6f-c6b1-035289b9371f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def build_dictionary():\n",
        "    path = 'train.csv'\n",
        "    dictionary, classes = build_label_dictionary(path)\n",
        "    n_classes = len(classes)\n",
        "    keys = np.array(list(dictionary.keys()))\n",
        "    return dictionary,classes,n_classes,keys\n",
        " \n",
        "dictionary,classes,n_classes,keys = build_dictionary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of unique classes:  [0, 1, 10, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsAyxP5-9wPq"
      },
      "source": [
        "train_generator = DataGenerator(dictionary=dictionary,\n",
        "                                threshold = threshold,\n",
        "                                normalize = False,\n",
        "                                layers = n_layers,\n",
        "                                data_path = train_path,\n",
        "                                batch_size = batch_size,\n",
        "                              n_classes=n_classes,\n",
        "                              feature_shapes=feature_shapes,\n",
        "                              n_anchors=n_anchors,\n",
        "                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8b5BI5fXbz",
        "outputId": "90544f04-0014-4efd-9e99-02a487924861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def build_dictionary():\n",
        "    path = 'val.csv'\n",
        "    dictionary, classes = build_label_dictionary(path)\n",
        "    n_classes = len(classes)\n",
        "    keys = np.array(list(dictionary.keys()))\n",
        "    return dictionary,classes,n_classes,keys\n",
        " \n",
        "dictionary1,classes1,n_classes,keys1 = build_dictionary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of unique classes:  [0, 1, 10, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUd5QWD7fRps"
      },
      "source": [
        "val_generator = Validation_DataGenerator(dictionary=dictionary1,\n",
        "                                threshold = threshold,\n",
        "                                normalize = False,\n",
        "                                layers = n_layers,\n",
        "                                data_path = val_path,\n",
        "                                batch_size = batch_size,\n",
        "                              n_classes=n_classes,\n",
        "                              feature_shapes=feature_shapes,\n",
        "                              n_anchors=n_anchors,\n",
        "                              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRITpPHm9wP0"
      },
      "source": [
        "# MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uF7kDz39wP1"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "name = \"LOL{}\".format(int(time.time()))\n",
        "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJCVPPh_9wP9"
      },
      "source": [
        "def print_log(param, verbose=0):\n",
        "    if verbose > 0:\n",
        "        print(param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ-d32Ng9wQN"
      },
      "source": [
        "# CHECKPOINT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsWuyC4W9wQQ"
      },
      "source": [
        "checkpoint_path = \"/content/drive/My\\ Drive/epoch-{epoch:02d}-loss-{loss:0.2f}.h5\"\n",
        " \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        " \n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq='epoch',\n",
        "                                                 verbose=1)\n",
        " \n",
        "#model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msJ0KOf29wQb",
        "outputId": "f0902960-79e3-459b-ba92-f806f55cac5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.65, beta_2=0.8, epsilon=1e-08)\n",
        " \n",
        "print_log(\"Focal loss and smooth L1\", verbose)\n",
        "loss = [focal_loss_categorical, smooth_l1_loss]\n",
        " \n",
        " \n",
        "model.compile(optimizer=optimizer, loss=loss,metrics = ['accuracy'])\n",
        " \n",
        "callbacks = [scheduler,tensorboard,cp_callback]\n",
        " \n",
        " \n",
        "model.fit(train_generator, callbacks=callbacks, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Focal loss and smooth L1\n",
            "Learning rate:  0.001\n",
            "Epoch 1/10\n",
            "    2/29976 [..............................] - ETA: 1:58:39 - loss: 0.0751 - concatenate_9_loss: 0.0061 - concatenate_8_loss: 0.0691 - concatenate_9_accuracy: 0.9607 - concatenate_8_accuracy: 0.4117WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0720s vs `on_train_batch_end` time: 0.4029s). Check your callbacks.\n",
            " 1591/29976 [>.............................] - ETA: 1:23:59 - loss: 0.1803 - concatenate_9_loss: 0.0129 - concatenate_8_loss: 0.1674 - concatenate_9_accuracy: 0.9962 - concatenate_8_accuracy: 0.4795"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjdkO65i9wQl"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGD3qao9wQn"
      },
      "source": [
        "# NON MAX SUPRESSION AND BOXES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd_SFCFS9wQp"
      },
      "source": [
        "\"\"\"def nms(classes, offsets, anchors):\n",
        "    objects = np.argmax(classes, axis=1)\n",
        "    # non-zero indexes are not background\n",
        "    nonbg = np.nonzero(objects)[0]\n",
        "\n",
        "    # D and S indexes in Line 1\n",
        "    indexes = []\n",
        "    while True:\n",
        "        # list of zero probability values\n",
        "        scores = np.zeros((classes.shape[0],))\n",
        "        # set probability values of non-background\n",
        "        scores[nonbg] = np.amax(classes[nonbg], axis=1)\n",
        "\n",
        "        # max probability given the list\n",
        "        # Lines 3 and 4\n",
        "        score_idx = np.argmax(scores, axis=0)\n",
        "        score_max = scores[score_idx]\n",
        "        \n",
        "        # get all non max probability & set it as new nonbg\n",
        "        # Line 5\n",
        "        nonbg = nonbg[nonbg != score_idx]\n",
        "\n",
        "        # if max obj probability is less than threshold (def 0.8)\n",
        "        if score_max < class_threshold:\n",
        "            # we are done\n",
        "            break\n",
        "\n",
        "        # Line 5\n",
        "        indexes.append(score_idx)\n",
        "        score_anc = anchors[score_idx]\n",
        "        score_off = offsets[score_idx][0:4]\n",
        "        score_box = score_anc + score_off\n",
        "        score_box = np.expand_dims(score_box, axis=0)\n",
        "        nonbg_copy = np.copy(nonbg)\n",
        "\n",
        "        # get all overlapping predictions (Line 6)\n",
        "        # perform Non-Max Suppression (NMS)\n",
        "        for idx in nonbg_copy:\n",
        "            anchor = anchors[idx]\n",
        "            offset = offsets[idx][0:4]\n",
        "            box = anchor + offset\n",
        "            box = np.expand_dims(box, axis=0)\n",
        "            iou1 = iou(box, score_box)[0][0]\n",
        "            # if soft NMS is chosen (Line 7)\n",
        "            if soft_nms:\n",
        "                # adjust score: Line 8\n",
        "                iou1 = -2 * iou1 * iou1\n",
        "                classes[idx] *= math.exp(iou1)\n",
        "            # else NMS (Line 9), (iou threshold def 0.2)\n",
        "            elif iou1 >= iou_threshold:\n",
        "                # remove overlapping predictions with iou>threshold\n",
        "                # Line 10\n",
        "                nonbg = nonbg[nonbg != idx]\n",
        "\n",
        "        # Line 2, nothing else to process\n",
        "        if nonbg.size == 0:\n",
        "            break\n",
        "\n",
        "\n",
        "    # get the array of object scores\n",
        "    scores = np.zeros((classes.shape[0],))\n",
        "    scores[indexes] = np.amax(classes[indexes], axis=1)\n",
        "\n",
        "    return objects, indexes, scores\n",
        "\n",
        "\n",
        "def show_boxes(simage, classes, offsets, feature_shapes, show=True):\n",
        "\n",
        "    # generate all anchor boxes per feature map\n",
        "    anchors = []\n",
        "    n_layers = len(feature_shapes)\n",
        "    for index, feature_shape in enumerate(feature_shapes):\n",
        "        anchor = anchor_boxes(feature_shape,\n",
        "                              image.shape,\n",
        "                              index=index)\n",
        "        anchor = np.reshape(anchor, [-1, 4])\n",
        "        if index == 0:\n",
        "            anchors = anchor\n",
        "        else:\n",
        "            anchors = np.concatenate((anchors, anchor), axis=0)\n",
        "\n",
        "    objects, indexes, scores = nms(classes,\n",
        "                                   offsets,\n",
        "                                   anchors)\n",
        "\n",
        "    class_names = []\n",
        "    rects = []\n",
        "    class_ids = []\n",
        "    boxes = []\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(1)\n",
        "        ax.imshow(image)\n",
        "    yoff = 1\n",
        "    for idx in indexes:\n",
        "        #batch, row, col, box\n",
        "        anchor = anchors[idx] \n",
        "        offset = offsets[idx]\n",
        "        \n",
        "        anchor += offset[0:4]\n",
        "        # default anchor box format is \n",
        "        # xmin, xmax, ymin, ymax\n",
        "        boxes.append(anchor)\n",
        "        w = anchor[1] - anchor[0]\n",
        "        h = anchor[3] - anchor[2]\n",
        "        x = anchor[0]\n",
        "        y = anchor[2]\n",
        "        category = int(objects[idx])\n",
        "        class_ids.append(category)\n",
        "        class_name = index2class(category)\n",
        "        class_name = \"%s: %0.2f\" % (class_name, scores[idx])\n",
        "        class_names.append(class_name)\n",
        "        rect = (x, y, w, h)\n",
        "        print(class_name, rect)\n",
        "        rects.append(rect)\n",
        "        if show:\n",
        "            color = get_box_color(category)\n",
        "            rect = Rectangle((x, y),\n",
        "                             w,\n",
        "                             h,\n",
        "                             linewidth=2,\n",
        "                             edgecolor=color,\n",
        "                             facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            bbox = dict(color='white',\n",
        "                        alpha=1.0)\n",
        "            ax.text(anchor[0] + 2,\n",
        "                    anchor[2] - 16 + np.random.randint(0,yoff),\n",
        "                    class_name,\n",
        "                    color=color,\n",
        "                    #fontweight='bold',\n",
        "                    bbox=bbox,\n",
        "                    fontsize=10,\n",
        "                    verticalalignment='top')\n",
        "            yoff += 50\n",
        "            #t.set_bbox(dict(facecolor='red', alpha=0.5, edgecolor='red'))\n",
        "\n",
        "    if show:\n",
        "        plt.savefig(\"detection.png\", dpi=600)\n",
        "        plt.show()\n",
        "\n",
        "    return class_names, rects, class_ids, boxes\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZld11B_9wQz"
      },
      "source": [
        "\"\"\"def detect_objects(image):\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    classes, offsets = model.predict(image)\n",
        "    image = np.squeeze(image, axis=0)\n",
        "    classes = np.squeeze(classes)\n",
        "    offsets = np.squeeze(offsets)\n",
        "    return image, classes, offsets\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3lzmlvO9wQ7"
      },
      "source": [
        "\"\"\"def get_box_rgbcolor(index=None):\n",
        "    colors = [(0, 0, 0), (255, 0, 0), (0, 0, 255), (0, 255, 0), (128, 128, 0)]\n",
        "    if index is None:\n",
        "        return colors[randint(0, len(colors) - 1)]\n",
        "    return colors[index % len(colors)]\n",
        "\n",
        "\n",
        "def index2class(index=0):\n",
        "    index = 0\n",
        "    classes = params['classes']\n",
        "    return classes[index]\n",
        "\n",
        "\n",
        "def class2index(class_=\"background\"):\n",
        "    classes = params['classes']\n",
        "    return classes.index(class_)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qA_OuzmE9wRD"
      },
      "source": [
        "\"\"\"show = True\n",
        "\n",
        "\n",
        "image = Image.open('/home/hritik/global-wheat-detection/test/aac893a91.jpg')\n",
        "image = image.resize((304,304))\n",
        "\n",
        "image = skimage.img_as_float(image)\n",
        "\n",
        "\n",
        "image, classes, offsets = detect_objects(image)\n",
        "class_names, rects, _, _ = show_boxes(image, classes, offsets, feature_shapes, show=show)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}